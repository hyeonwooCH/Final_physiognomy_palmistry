{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPQlwQKXi7WpeZ2ypEEMNZq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyeonwooCH/Final_physiognomy_palmistry/blob/main/segface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 저장소 클론\n",
        "!git clone https://github.com/Kartik-3004/SegFace.git\n",
        "%cd SegFace\n",
        "\n",
        "# 2. 필수 라이브러리 설치\n",
        "# environment.yml 기반으로 설치해야 하지만, 코랩 기본 환경을 고려해 필수 패키지만 설치합니다.\n",
        "!pip install timm segmentation-models-pytorch albumentations python-dotenv"
      ],
      "metadata": {
        "id": "3F4VZCZpEcr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 현재 경로 확인\n",
        "root_path = os.getcwd()\n",
        "\n",
        "# .env 파일 생성\n",
        "with open(\".env\", \"w\") as f:\n",
        "    f.write(f\"ROOT_PATH={root_path}\\n\")\n",
        "    f.write(f\"DATA_PATH={root_path}/data\\n\")\n",
        "    f.write(f\"LOG_PATH={root_path}/logs\\n\")\n",
        "\n",
        "print(\".env 파일 생성 완료\")"
      ],
      "metadata": {
        "id": "pE86lpajFBMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "hf_hub_download(repo_id=\"kartiknarayan/SegFace\", filename=\"convnext_celeba_512/model_299.pt\", local_dir=\"./weights\")"
      ],
      "metadata": {
        "id": "KT6f7eVLFXFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# .env 파일 생성 재확인\n",
        "with open(\".env\", \"w\") as f:\n",
        "    f.write(f\"ROOT_PATH=/content/SegFace\\n\")\n",
        "    f.write(f\"DATA_PATH=/content/SegFace/data\\n\")\n",
        "    f.write(f\"LOG_PATH=/content/SegFace/logs\\n\")\n",
        "\n",
        "load_dotenv()\n",
        "print(f\"ROOT_PATH: {os.getenv('ROOT_PATH')}\")"
      ],
      "metadata": {
        "id": "DtEedAi4Gzuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# 1. 경로 설정 및 모듈 임포트\n",
        "%cd /content/SegFace\n",
        "if '/content/SegFace' not in sys.path:\n",
        "    sys.path.append('/content/SegFace')\n",
        "\n",
        "# 수정된 경로로 클래스 임포트\n",
        "from network.models.segface_celeb import SegFaceCeleb\n",
        "\n",
        "# 2. 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_path = \"/content/SegFace/weights/convnext_celeba_512/model_299.pt\"\n",
        "image_path = \"/content/mememe_fixed.jpg\" # input 바꾸기\n",
        "input_res = 512\n",
        "\n",
        "# 3. 모델 초기화 및 가중치 로드\n",
        "model = SegFaceCeleb(input_res, \"convnext_base\")\n",
        "\n",
        "checkpoint = torch.load(model_path, map_location=device)\n",
        "\n",
        "# 가중치 키 추출 (에러 메시지에 기반하여 state_dict_backbone 등을 확인)\n",
        "if 'state_dict_backbone' in checkpoint:\n",
        "    print(\"state_dict_backbone 키를 발견했습니다.\")\n",
        "    # 저장소의 특이한 구조에 맞춰 가중치를 결합해야 할 수도 있습니다.\n",
        "    # 일단 가장 확률이 높은 모델 가중치 키를 시도합니다.\n",
        "    pretrained_dict = checkpoint['state_dict_backbone']\n",
        "else:\n",
        "    # 일반적인 경우\n",
        "    pretrained_dict = checkpoint.get('model_state_dict', checkpoint)\n",
        "\n",
        "# 현재 모델의 state_dict 가져오기\n",
        "model_dict = model.state_dict()\n",
        "\n",
        "# 가중치 이름이 'backbone.'으로 시작하지 않는 경우를 대비해 필터링 (필요 시)\n",
        "# 아래는 키 이름이 매칭되지 않을 때 강제로 로드하기 위한 설정입니다.\n",
        "model.load_state_dict(pretrained_dict, strict=False)\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "print(\"모델 로드 완료!\")\n",
        "\n",
        "# 4. 이미지 전처리\n",
        "img_raw = Image.open(image_path).convert('RGB')\n",
        "img_resized = img_raw.resize((input_res, input_res))\n",
        "input_tensor = torch.from_numpy(np.array(img_resized)).permute(2, 0, 1).float().div(255).unsqueeze(0).to(device)\n",
        "\n",
        "# 5. 추론 (Forward)\n",
        "with torch.no_grad():\n",
        "    # 소스 코드의 forward(self, x, labels, dataset) 구조에 대응\n",
        "    # labels는 딕셔너리 형태, dataset은 텐서 형태의 더미 데이터를 넣어줍니다.\n",
        "    dummy_labels = {}\n",
        "    dummy_dataset = torch.tensor([0]).to(device)\n",
        "\n",
        "    output = model(input_tensor, dummy_labels, dummy_dataset)\n",
        "\n",
        "    # SegFaceCeleb은 최종적으로 seg_output (텐서)을 반환합니다.\n",
        "    if isinstance(output, (list, tuple)):\n",
        "        output = output[0]\n",
        "\n",
        "    pred = torch.argmax(output, dim=1).squeeze().cpu().numpy()\n",
        "\n",
        "# 6. 결과 시각화\n",
        "# 6. 통합 시각화 (원본 | 결과 | 오버레이)\n",
        "plt.figure(figsize=(18, 6)) # 가로로 길게 배치\n",
        "\n",
        "# (1) 원본 이미지\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(img_resized)\n",
        "plt.axis('off')\n",
        "\n",
        "# (2) 세그멘테이션 결과 (Mask)\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.title(\"SegFace Prediction\")\n",
        "plt.imshow(pred, cmap='tab20')\n",
        "plt.axis('off')\n",
        "\n",
        "# (3) 오버레이 결과 (Original + Mask)\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.title(\"SegFace Overlay\")\n",
        "plt.imshow(img_resized) # 먼저 배경에 원본을 깔고\n",
        "plt.imshow(pred, cmap='tab20', alpha=0.5) # 그 위에 투명도(alpha)를 줘서 출력\n",
        "plt.axis('off')\n",
        "\n",
        "# 레이아웃 정렬 및 저장\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"/content/SegFace_combined_result.png\", bbox_inches='tight', pad_inches=0.1)\n",
        "plt.show()\n",
        "\n",
        "print(\"모든 결과가 통합되어 /content/SegFace_combined_result.png 에 저장되었습니다.\")"
      ],
      "metadata": {
        "id": "EAmPY9WEGsnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 코랩 셀에 이 코드 붙이기\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image, ImageOps\n",
        "import subprocess\n",
        "\n",
        "# 원본 이미지 경로\n",
        "input_image_path = \"/content/mememe.jpg\"\n",
        "\n",
        "# EXIF 회전 처리된 이미지 저장할 임시 경로\n",
        "fixed_image_path = \"/content/mememe_fixed.jpg\"\n",
        "\n",
        "# 1단계: EXIF 처리\n",
        "img = Image.open(input_image_path)\n",
        "img = ImageOps.exif_transpose(img)  # ★ 회전 적용\n",
        "img.save(fixed_image_path)\n",
        "\n",
        "print(\"✅ EXIF 처리 + 추론 완료!\")\n"
      ],
      "metadata": {
        "id": "Dubpgay2HA5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MiDaS 모델을 이용한 간단한 깊이(Depth) 추출 예시\n",
        "import torch\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. 모델 로드 (가장 가벼운 버전)\n",
        "model_type = \"MiDaS_small\"\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n",
        "midas.to('cuda').eval()\n",
        "\n",
        "# 2. 이미지 변환 설정\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "transform = midas_transforms.small_transform if model_type == \"MiDaS_small\" else midas_transforms.dpt_transform\n",
        "\n",
        "# 3. 깊이 추론\n",
        "img = cv2.imread('/content/me4.jpg')\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "input_batch = transform(img).to('cuda')\n",
        "\n",
        "with torch.no_grad():\n",
        "    prediction = midas(input_batch)\n",
        "    prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "    ).squeeze()\n",
        "\n",
        "depth_map = prediction.cpu().numpy()\n",
        "\n",
        "# 4. 결과 출력\n",
        "plt.imshow(depth_map, cmap='magma')\n",
        "plt.title(\"3D Depth Map\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hH67Xtv_I1B7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aqMNaFLqwgVD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}