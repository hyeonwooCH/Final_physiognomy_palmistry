{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6cprQ3vuVDVcjQsJW18SM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyeonwooCH/Final_physiognomy_palmistry/blob/main/Algorithm_by_SegFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터셋 로드"
      ],
      "metadata": {
        "id": "48gywwTsFcoP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAXhfFETEZqG"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 경로 설정\n",
        "import os\n",
        "import glob\n",
        "\n",
        "test_base_path = \"/content/drive/MyDrive/c. Final_Team/Split_dataset/test\"\n",
        "test_images_path = os.path.join(test_base_path, \"images\")\n",
        "test_masks_path = os.path.join(test_base_path, \"masks\")"
      ],
      "metadata": {
        "id": "SwnttkdoIC5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SegFace 로드"
      ],
      "metadata": {
        "id": "tqQy-40XKlhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. SegFace 저장소 클론 및 이동\n",
        "!git clone https://github.com/Kartik-3004/SegFace.git\n",
        "%cd SegFace\n",
        "\n",
        "# 2. 필수 라이브러리 설치 (코랩 환경 최적화 버전)\n",
        "!pip install -q timm==0.9.12 segmentation-models-pytorch albumentations python-dotenv huggingface_hub"
      ],
      "metadata": {
        "id": "Dr_TdyrtKnsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# 1. .env 경로 설정 파일 생성\n",
        "root_path = \"/content/SegFace\"\n",
        "with open(\".env\", \"w\") as f:\n",
        "    f.write(f\"ROOT_PATH={root_path}\\n\")\n",
        "    f.write(f\"DATA_PATH={root_path}/data\\n\")\n",
        "    f.write(f\"LOG_PATH={root_path}/logs\\n\")\n",
        "\n",
        "# 2. 가중치(Weights) 다운로드\n",
        "hf_hub_download(repo_id=\"kartiknarayan/SegFace\",\n",
        "                filename=\"convnext_celeba_512/model_299.pt\",\n",
        "                local_dir=\"./weights\")\n",
        "\n",
        "print(\"✅ 환경 설정 및 가중치 다운로드 완료!\")"
      ],
      "metadata": {
        "id": "GcFPLposK1CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# 1. 경로 설정 및 모듈 임포트\n",
        "%cd /content/SegFace\n",
        "if '/content/SegFace' not in sys.path:\n",
        "    sys.path.append('/content/SegFace')\n",
        "\n",
        "# 수정된 경로로 클래스 임포트\n",
        "from network.models.segface_celeb import SegFaceCeleb\n",
        "\n",
        "# 2. 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_path = \"/content/SegFace/weights/convnext_celeba_512/model_299.pt\"\n",
        "image_path = \"/content/mememe_fixed.jpg\" # input 바꾸기\n",
        "input_res = 512\n",
        "\n",
        "# 3. 모델 초기화 및 가중치 로드\n",
        "model = SegFaceCeleb(input_res, \"convnext_base\")\n",
        "\n",
        "checkpoint = torch.load(model_path, map_location=device)\n",
        "\n",
        "# 가중치 키 추출 (에러 메시지에 기반하여 state_dict_backbone 등을 확인)\n",
        "if 'state_dict_backbone' in checkpoint:\n",
        "    print(\"state_dict_backbone 키를 발견했습니다.\")\n",
        "    # 저장소의 특이한 구조에 맞춰 가중치를 결합해야 할 수도 있습니다.\n",
        "    # 일단 가장 확률이 높은 모델 가중치 키를 시도합니다.\n",
        "    pretrained_dict = checkpoint['state_dict_backbone']\n",
        "else:\n",
        "    # 일반적인 경우\n",
        "    pretrained_dict = checkpoint.get('model_state_dict', checkpoint)\n",
        "\n",
        "# 현재 모델의 state_dict 가져오기\n",
        "model_dict = model.state_dict()\n",
        "\n",
        "# 가중치 이름이 'backbone.'으로 시작하지 않는 경우를 대비해 필터링 (필요 시)\n",
        "# 아래는 키 이름이 매칭되지 않을 때 강제로 로드하기 위한 설정입니다.\n",
        "model.load_state_dict(pretrained_dict, strict=False)\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "print(\"모델 로드 완료!\")"
      ],
      "metadata": {
        "id": "_stTB79fK42M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 눈썹 알고리즘"
      ],
      "metadata": {
        "id": "KUpuGtw9Mezd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_path = \"/content/SegFace/weights/convnext_celeba_512/model_299.pt\"\n",
        "input_res = 512\n",
        "\n",
        "# SegFace 모델 초기화 (작성하신 방식 적용)\n",
        "model = SegFaceCeleb(input_res, \"convnext_base\")\n",
        "checkpoint = torch.load(model_path, map_location=device)\n",
        "pretrained_dict = checkpoint.get('state_dict_backbone', checkpoint.get('model_state_dict', checkpoint))\n",
        "model.load_state_dict(pretrained_dict, strict=False)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "print(\"모델 로드 및 준비 완료!\")\n",
        "\n",
        "# --- [새로운 분석 함수 정의] ---\n",
        "\n",
        "def analyze_new_image(img_path, model, device):\n",
        "    # 1. 이미지 로드 및 전처리\n",
        "    img = Image.open(img_path).convert('RGB').resize((512, 512))\n",
        "    img_np = np.array(img)\n",
        "\n",
        "    # 모델 입력용 텐서 변환 (SegFace는 보통 [0, 1] 범위를 기대함)\n",
        "    input_tensor = torch.from_numpy(img_np).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
        "    input_tensor = input_tensor.to(device)\n",
        "\n",
        "    # 2. 모델 추론\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor, None, None)\n",
        "        # output이 list나 tuple로 올 경우를 대비해 마지막 segmentation map 선택\n",
        "        if isinstance(output, (list, tuple)):\n",
        "            output = output[-1]\n",
        "\n",
        "        # 클래스 예측 (Channel-wise Argmax)\n",
        "        mask_predict = torch.argmax(output, dim=1).squeeze().cpu().numpy()\n",
        "\n",
        "    # 3. 관상 분석 로직 (눈썹/눈 마스크 추출)\n",
        "    # SegFace/CelebA 라벨 기준: 7:L-Eyebrow, 6:R-Eyebrow, 9:L-Eye, 8:R-Eye\n",
        "    l_eb_mask = (mask_predict == 7).astype(np.uint8)\n",
        "    r_eb_mask = (mask_predict == 6).astype(np.uint8)\n",
        "    l_eye_mask = (mask_predict == 9).astype(np.uint8)\n",
        "\n",
        "    def get_bbox_info(m):\n",
        "        coords = np.column_stack(np.where(m > 0))\n",
        "        if len(coords) == 0: return None\n",
        "        return {'min_y': np.min(coords[:, 0]), 'min_x': np.min(coords[:, 1]),\n",
        "                'max_y': np.max(coords[:, 0]), 'max_x': np.max(coords[:, 1]),\n",
        "                'coords': coords}\n",
        "\n",
        "    l_eb = get_bbox_info(l_eb_mask)\n",
        "    r_eb = get_bbox_info(r_eb_mask)\n",
        "    l_eye = get_bbox_info(l_eye_mask)\n",
        "\n",
        "    analysis = {}\n",
        "    if l_eb and r_eb and l_eye:\n",
        "        # 미간 너비 (인당)\n",
        "        analysis['glabella_width'] = r_eb['min_x'] - l_eb['max_x']\n",
        "        # 눈썹 길이 비율\n",
        "        eye_w = l_eye['max_x'] - l_eye['min_x']\n",
        "        eb_w = l_eb['max_x'] - l_eb['min_x']\n",
        "        analysis['length_ratio'] = eb_w / eye_w if eye_w > 0 else 0\n",
        "        # 눈썹 기울기\n",
        "        pts = l_eb['coords']\n",
        "        head = pts[np.argmin(pts[:, 1])] # 가장 왼쪽\n",
        "        tail = pts[np.argmax(pts[:, 1])] # 가장 오른쪽\n",
        "        analysis['tilt'] = np.degrees(np.arctan2(head[0] - tail[0], tail[1] - head[1]))\n",
        "        # 전택궁 거리\n",
        "        analysis['palace_dist'] = l_eye['min_y'] - l_eb['max_y']\n",
        "    else:\n",
        "        analysis = None\n",
        "\n",
        "    return img_np, mask_predict, analysis\n",
        "\n",
        "# --- [실행 및 시각화] ---\n",
        "\n",
        "test_img = \"/content/h2_temp.jpg\" # 실제 파일 경로\n",
        "img_res, mask_res, res = analyze_new_image(test_img, model, device)\n",
        "\n",
        "if res:\n",
        "    plt.figure(figsize=(15, 7))\n",
        "\n",
        "    # 1. 원본 이미지 + 특정 부위 오버레이\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img_res)\n",
        "    # 눈(4,5)과 눈썹(2,3) 영역만 색칠해서 표시\n",
        "    overlay = np.zeros_like(img_res)\n",
        "    overlay[np.isin(mask_res, [6, 7])] = [255, 0, 0] # 눈썹은 빨강\n",
        "    overlay[np.isin(mask_res, [8, 9])] = [0, 255, 0] # 눈은 초록\n",
        "    plt.imshow(overlay, alpha=0.3)\n",
        "    plt.title(\"Detected Features\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # 2. 분석 결과 시각화\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(img_res)\n",
        "    info_text = (f\"Glabella: {res['glabella_width']}px\\n\"\n",
        "                 f\"Length Ratio: {res['length_ratio']:.2f}\\n\"\n",
        "                 f\"Tilt: {res['tilt']:.1f}°\\n\"\n",
        "                 f\"Palace Dist: {res['palace_dist']}px\")\n",
        "    plt.text(10, 80, info_text, color='white', fontsize=12, fontweight='bold',\n",
        "             bbox=dict(facecolor='black', alpha=0.6))\n",
        "    plt.title(\"Physiognomy Analysis\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"눈썹 또는 눈 검출에 실패했습니다. 마스크를 확인하세요.\")"
      ],
      "metadata": {
        "id": "xLwUBdN-Mhut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# --- [모델 로드 부분은 기존과 동일하게 유지] ---\n",
        "# ... (생략: model, checkpoint 로드 로직)\n",
        "\n",
        "def analyze_new_image(img_path, model, device):\n",
        "    img = Image.open(img_path).convert('RGB').resize((512, 512))\n",
        "    img_np = np.array(img)\n",
        "\n",
        "    input_tensor = torch.from_numpy(img_np).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
        "    input_tensor = input_tensor.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor, None, None)\n",
        "        if isinstance(output, (list, tuple)):\n",
        "            output = output[-1]\n",
        "        mask_predict = torch.argmax(output, dim=1).squeeze().cpu().numpy()\n",
        "\n",
        "    # 1. 마스크 추출\n",
        "    l_eb_mask = (mask_predict == 7).astype(np.uint8)\n",
        "    r_eb_mask = (mask_predict == 6).astype(np.uint8)\n",
        "    l_eye_mask = (mask_predict == 9).astype(np.uint8)\n",
        "\n",
        "    def get_bbox_info(m):\n",
        "        coords = np.column_stack(np.where(m > 0))\n",
        "        if len(coords) == 0: return None\n",
        "        return {'min_y': np.min(coords[:, 0]), 'min_x': np.min(coords[:, 1]),\n",
        "                'max_y': np.max(coords[:, 0]), 'max_x': np.max(coords[:, 1]),\n",
        "                'coords': coords}\n",
        "\n",
        "    l_eb = get_bbox_info(l_eb_mask)\n",
        "    r_eb = get_bbox_info(r_eb_mask)\n",
        "    l_eye = get_bbox_info(l_eye_mask)\n",
        "\n",
        "    analysis = {}\n",
        "    if l_eb and r_eb and l_eye:\n",
        "        # 2. 관상 수치 계산\n",
        "        analysis['glabella_width'] = r_eb['min_x'] - l_eb['max_x']\n",
        "        eye_w = l_eye['max_x'] - l_eye['min_x']\n",
        "        eb_w = l_eb['max_x'] - l_eb['min_x']\n",
        "        analysis['length_ratio'] = eb_w / eye_w if eye_w > 0 else 0\n",
        "\n",
        "        pts = l_eb['coords']\n",
        "        head = pts[np.argmin(pts[:, 1])]\n",
        "        tail = pts[np.argmax(pts[:, 1])]\n",
        "        analysis['tilt'] = np.degrees(np.arctan2(head[0] - tail[0], tail[1] - head[1]))\n",
        "        analysis['palace_dist'] = l_eye['min_y'] - l_eb['max_y']\n",
        "\n",
        "        # 3. [추가] 시각화를 위한 좌표 데이터 저장\n",
        "        analysis['coords'] = {\n",
        "            'l_eb_edge': l_eb['max_x'], # 왼쪽 눈썹 오른쪽 끝 x\n",
        "            'r_eb_edge': r_eb['min_x'], # 오른쪽 눈썹 왼쪽 끝 x\n",
        "            'eb_mid_y': (l_eb['min_y'] + l_eb['max_y']) // 2, # 눈썹 중간 높이\n",
        "            'l_eb_bottom_y': l_eb['max_y'], # 눈썹 하단 y\n",
        "            'l_eye_top_y': l_eye['min_y'],  # 눈 상단 y\n",
        "            'l_eye_mid_x': (l_eye['min_x'] + l_eye['max_x']) // 2 # 눈 중앙 x\n",
        "        }\n",
        "    else:\n",
        "        analysis = None\n",
        "\n",
        "    return img_np, mask_predict, analysis\n",
        "\n",
        "# --- [시각화 부분 수정] ---\n",
        "\n",
        "test_img = \"/content/h2_temp.jpg\"\n",
        "img_res, mask_res, res = analyze_new_image(test_img, model, device)\n",
        "\n",
        "if res:\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(img_res)\n",
        "\n",
        "    # 1. 눈/눈썹 영역 하이라이트 (투명 오버레이)\n",
        "    overlay = np.zeros_like(img_res)\n",
        "    overlay[np.isin(mask_res, [6, 7])] = [255, 0, 0] # Red (Eyebrows)\n",
        "    overlay[np.isin(mask_res, [8, 9])] = [0, 255, 0] # Green (Eyes)\n",
        "    plt.imshow(overlay, alpha=0.3)\n",
        "\n",
        "    c = res['coords']\n",
        "\n",
        "    # 2. 미간 너비(Glabella) 시각화 (파란색 선)\n",
        "    plt.plot([c['l_eb_edge'], c['r_eb_edge']], [c['eb_mid_y'], c['eb_mid_y']],\n",
        "             color='cyan', linestyle='-', linewidth=2, marker='|', markersize=10)\n",
        "    plt.text((c['l_eb_edge'] + c['r_eb_edge']) // 2, c['eb_mid_y'] - 10,\n",
        "             f\"Glabella: {res['glabella_width']}px\", color='cyan',\n",
        "             fontsize=10, fontweight='bold', ha='center')\n",
        "\n",
        "    # 3. 전택궁(Palace Dist) 시각화 (노란색 화살표)\n",
        "    # 왼쪽 눈 위쪽 기준으로 표시\n",
        "    plt.annotate('', xy=(c['l_eye_mid_x'], c['l_eye_top_y']),\n",
        "                 xytext=(c['l_eye_mid_x'], c['l_eb_bottom_y']),\n",
        "                 arrowprops=dict(arrowstyle='<->', color='yellow', lw=2))\n",
        "    plt.text(c['l_eye_mid_x'] + 10, (c['l_eb_bottom_y'] + c['l_eye_top_y']) // 2,\n",
        "             f\"Palace: {res['palace_dist']}px\", color='yellow',\n",
        "             fontsize=10, fontweight='bold', va='center')\n",
        "\n",
        "    # 4. 분석 결과 텍스트 요약박스\n",
        "    info_text = (f\"Glabella: {res['glabella_width']}px\\n\"\n",
        "                 f\"Palace Dist: {res['palace_dist']}px\\n\"\n",
        "                 f\"Tilt: {res['tilt']:.1f}°\\n\"\n",
        "                 f\"Length Ratio: {res['length_ratio']:.2f}\")\n",
        "    plt.text(20, 490, info_text, color='white', fontsize=12, fontweight='bold',\n",
        "             bbox=dict(facecolor='black', alpha=0.7, edgecolor='white'))\n",
        "\n",
        "    plt.title(\"Eyebrow & Eye Physiognomy Measurement\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"분석 실패\")"
      ],
      "metadata": {
        "id": "46Pd40MCNgy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 코랩 셀에 이 코드 붙이기\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image, ImageOps\n",
        "import subprocess\n",
        "\n",
        "# 원본 이미지 경로\n",
        "input_image_path = \"/content/toy.jpg\"\n",
        "\n",
        "# EXIF 회전 처리된 이미지 저장할 임시 경로\n",
        "fixed_image_path = \"/content/toy_temp.jpg\"\n",
        "\n",
        "# 1단계: EXIF 처리\n",
        "img = Image.open(input_image_path)\n",
        "img = ImageOps.exif_transpose(img)  # ★ 회전 적용\n",
        "img.save(fixed_image_path)\n",
        "\n",
        "print(\"✅ EXIF 처리 + 추론 완료!\")\n"
      ],
      "metadata": {
        "id": "gIDnxZmVSoBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 이마 알고리즘"
      ],
      "metadata": {
        "id": "pmz53dnKW-uh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# --- [1. 모델 추론 기반 이마 분석 함수] ---\n",
        "\n",
        "def analyze_forehead_predict(img_path, model, device):\n",
        "    # 이미지 로드 및 전처리\n",
        "    img = Image.open(img_path).convert('RGB').resize((512, 512))\n",
        "    img_np = np.array(img)\n",
        "    gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    input_tensor = torch.from_numpy(img_np).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
        "    input_tensor = input_tensor.to(device)\n",
        "\n",
        "    # 모델 추론\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor, None, None)\n",
        "        if isinstance(output, (list, tuple)):\n",
        "            output = output[-1]\n",
        "        mask_predict = torch.argmax(output, dim=1).squeeze().cpu().numpy()\n",
        "\n",
        "    # 라벨 정의: Skin=2, L_brow=6, R_brow=7 (SegFace/CelebA 표준)\n",
        "    skin_mask = (mask_predict == 2).astype(np.uint8)\n",
        "    brow_mask = np.isin(mask_predict, [6, 7]).astype(np.uint8)\n",
        "\n",
        "    def get_coords(m):\n",
        "        return np.column_stack(np.where(m > 0))\n",
        "\n",
        "    skin_pts = get_coords(skin_mask)\n",
        "    brow_pts = get_coords(brow_mask)\n",
        "\n",
        "    analysis = {}\n",
        "    if len(skin_pts) > 0 and len(brow_pts) > 0:\n",
        "        # --- 영역 및 좌표 정의 ---\n",
        "        face_top_y = np.min(skin_pts[:, 0])     # 헤어라인 최상단 (발제)\n",
        "        face_bottom_y = np.max(skin_pts[:, 0])  # 턱 끝\n",
        "        brow_top_y = np.min(brow_pts[:, 0])     # 눈썹 상단 라인\n",
        "        x_start, x_end = np.min(skin_pts[:, 1]), np.max(skin_pts[:, 1])\n",
        "        mid_x = (x_start + x_end) // 2\n",
        "\n",
        "        # 1. 이마 높이 비율 (상정 비율)\n",
        "        forehead_h = brow_top_y - face_top_y\n",
        "        face_h = face_bottom_y - face_top_y\n",
        "        analysis['forehead_ratio'] = forehead_h / face_h\n",
        "\n",
        "        # 2. 발제선(Hairline) 형태 분석 (M자형 판별)\n",
        "        hairline_pts = []\n",
        "        # 이마 좌우 20%를 제외한 구간에서 최상단 피부 좌표 샘플링\n",
        "        for x in range(x_start + 50, x_end - 50, 5):\n",
        "            y_vals = np.where(skin_mask[:brow_top_y, x] > 0)[0]\n",
        "            if len(y_vals) > 0:\n",
        "                hairline_pts.append((x, y_vals[0]))\n",
        "\n",
        "        if len(hairline_pts) > 10:\n",
        "            y_only = [p[1] for p in hairline_pts]\n",
        "            edge_avg = (y_only[0] + y_only[-1]) / 2\n",
        "            mid_val = y_only[len(y_only)//2]\n",
        "            # 중앙이 양끝보다 내려와 있으면 M자 (여기서는 임계값 15px)\n",
        "            analysis['is_m_shape'] = mid_val > edge_avg + 15\n",
        "            analysis['hairline_coords'] = hairline_pts\n",
        "        else:\n",
        "            analysis['is_m_shape'] = False\n",
        "            analysis['hairline_coords'] = []\n",
        "\n",
        "        # 3. 대칭성 및 중앙 밝기\n",
        "        left_area = np.sum(skin_mask[:brow_top_y, x_start:mid_x])\n",
        "        right_area = np.sum(skin_mask[:brow_top_y, mid_x:x_end])\n",
        "        analysis['symmetry'] = min(left_area, right_area) / max(left_area, right_area) if max(left_area, right_area) > 0 else 0\n",
        "\n",
        "        center_y = (face_top_y + brow_top_y) // 2\n",
        "        center_roi = gray[max(0, center_y-20):min(512, center_y+20), max(0, mid_x-20):min(512, mid_x+20)]\n",
        "        analysis['center_brightness'] = np.mean(center_roi) if center_roi.size > 0 else 0\n",
        "\n",
        "        # 시각화용 추가 좌표\n",
        "        analysis['viz_pts'] = {'face_top_y': face_top_y, 'brow_top_y': brow_top_y, 'mid_x': mid_x}\n",
        "    else:\n",
        "        analysis = None\n",
        "\n",
        "    return img_np, mask_predict, analysis\n",
        "\n",
        "# --- [2. 실행 및 시각화] ---\n",
        "\n",
        "test_img = \"/content/h2_temp.jpg\" # 실제 파일 경로\n",
        "img_res, mask_res, res = analyze_forehead_predict(test_img, model, device)\n",
        "\n",
        "if res:\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(img_res)\n",
        "\n",
        "    # A. 이마 영역 오버레이 (피부 중 눈썹 위 영역)\n",
        "    v = res['viz_pts']\n",
        "    forehead_mask = (mask_res == 1) & (np.indices((512, 512))[0] < v['brow_top_y'])\n",
        "    overlay = np.zeros((*img_res.shape[:2], 4), dtype=np.uint8)\n",
        "    overlay[forehead_mask] = [0, 255, 255, 80] # Cyan 투명 오버레이\n",
        "    plt.imshow(overlay)\n",
        "\n",
        "    # B. 헤어라인(Hairline) 선 그리기\n",
        "    if res['hairline_coords']:\n",
        "        h_pts = np.array(res['hairline_coords'])\n",
        "        plt.plot(h_pts[:, 0], h_pts[:, 1], color='magenta', linewidth=2, label='Hairline')\n",
        "\n",
        "    # C. 수직 비율 표시 (상정 높이)\n",
        "    plt.annotate('', xy=(v['mid_x'], v['brow_top_y']), xytext=(v['mid_x'], v['face_top_y']),\n",
        "                 arrowprops=dict(arrowstyle='<->', color='yellow', lw=2))\n",
        "    plt.text(v['mid_x'] + 10, (v['face_top_y'] + v['brow_top_y']) // 2,\n",
        "             f\"Forehead H: {v['brow_top_y'] - v['face_top_y']}px\", color='yellow', fontweight='bold')\n",
        "\n",
        "    # D. 결과 텍스트 요약\n",
        "    m_text = \"M-Shape (M자형)\" if res['is_m_shape'] else \"Round/Straight\"\n",
        "    info_text = (f\"[Forehead Analysis]\\n\"\n",
        "                 f\"Shape: {m_text}\\n\"\n",
        "                 f\"Ratio: {res['forehead_ratio']:.2f}\\n\"\n",
        "                 f\"Symmetry: {res['symmetry']:.2f}\\n\"\n",
        "                 f\"Brightness: {res['center_brightness']:.1f}\")\n",
        "\n",
        "    plt.text(20, 490, info_text, color='white', fontsize=12, fontweight='bold',\n",
        "             bbox=dict(facecolor='black', alpha=0.7, edgecolor='white'))\n",
        "\n",
        "    plt.title(\"Forehead Physiognomy Prediction\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"이마 영역 검출 실패\")"
      ],
      "metadata": {
        "id": "cGgToziZXAiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 눈 알고리즘"
      ],
      "metadata": {
        "id": "eQsT-WIgwu6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# --- [1. 모델 추론 기반 눈 분석 함수] ---\n",
        "\n",
        "def analyze_eye_predict(img_path, model, device):\n",
        "    # 이미지 로드 및 전처리\n",
        "    img = Image.open(img_path).convert('RGB').resize((512, 512))\n",
        "    img_np = np.array(img)\n",
        "    gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    input_tensor = torch.from_numpy(img_np).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
        "    input_tensor = input_tensor.to(device)\n",
        "\n",
        "    # 모델 추론\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor, None, None)\n",
        "        if isinstance(output, (list, tuple)):\n",
        "            output = output[-1]\n",
        "        mask_predict = torch.argmax(output, dim=1).squeeze().cpu().numpy()\n",
        "\n",
        "    # 라벨 정의: 8: 왼쪽 눈(L_eye), 9: 오른쪽 눈(R_eye)\n",
        "    # 여기서는 왼쪽 눈을 기준으로 상세 분석을 진행합니다.\n",
        "    l_eye_mask = (mask_predict == 9).astype(np.uint8)\n",
        "\n",
        "    def get_eye_details(eye_mask, gray_img):\n",
        "        coords = np.column_stack(np.where(eye_mask > 0))\n",
        "        if len(coords) < 10: return None\n",
        "\n",
        "        ymin, xmin, ymax, xmax = np.min(coords[:, 0]), np.min(coords[:, 1]), np.max(coords[:, 0]), np.max(coords[:, 1])\n",
        "        w = xmax - xmin\n",
        "        h = ymax - ymin\n",
        "\n",
        "        # 1. 기하학적 구조: 가로세로비 및 눈꼬리 각도\n",
        "        l_ratio = w / h if h > 0 else 0\n",
        "        head_pt = coords[np.argmin(coords[:, 1])] # 가장 왼쪽 점\n",
        "        tail_pt = coords[np.argmax(coords[:, 1])] # 가장 오른쪽 점\n",
        "        theta_tail = np.degrees(np.arctan2(head_pt[0] - tail_pt[0], tail_pt[1] - head_pt[1]))\n",
        "\n",
        "        # 2. 흑백 및 안광 분석\n",
        "        eye_roi = gray_img[ymin:ymax, xmin:xmax]\n",
        "        # 검은자위 비중 추정 (상위 30% 어두운 영역)\n",
        "        _, iris_bin = cv2.threshold(eye_roi, np.percentile(eye_roi, 30), 255, cv2.THRESH_BINARY_INV)\n",
        "        r_iris = np.sum(iris_bin/255) / (w * h)\n",
        "\n",
        "        # 안광(Specular Highlight) 추출\n",
        "        _, highlight_bin = cv2.threshold(eye_roi, 240, 255, cv2.THRESH_BINARY)\n",
        "        specular_strong = np.sum(highlight_bin) > 0\n",
        "\n",
        "        # 3. 수분감 (Reflectance)\n",
        "        std_val = np.std(eye_roi)\n",
        "        is_watery = std_val < 15 and np.mean(eye_roi) > 100\n",
        "\n",
        "        return {\n",
        "            \"l_ratio\": l_ratio,\n",
        "            \"theta_tail\": theta_tail,\n",
        "            \"r_iris\": r_iris,\n",
        "            \"specular\": specular_strong,\n",
        "            \"is_watery\": is_watery,\n",
        "            \"bbox\": [ymin, xmin, ymax, xmax],\n",
        "            \"points\": {\"head\": head_pt, \"tail\": tail_pt}\n",
        "        }\n",
        "\n",
        "    analysis = {}\n",
        "    analysis['left_eye'] = get_eye_details(l_eye_mask, gray)\n",
        "\n",
        "    return img_np, mask_predict, analysis\n",
        "\n",
        "# --- [2. 실행 및 상세 시각화] ---\n",
        "\n",
        "test_img = \"/content/fixed_image_temp.jpg\"\n",
        "img_res, mask_res, res = analyze_eye_predict(test_img, model, device)\n",
        "eye = res['left_eye']\n",
        "\n",
        "if eye:\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    # A. 전체 얼굴 내 눈 위치 표시\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img_res)\n",
        "    ymin, xmin, ymax, xmax = eye['bbox']\n",
        "    # 눈 영역 박스 표시\n",
        "    rect = plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, linewidth=1, edgecolor='yellow', facecolor='none')\n",
        "    plt.gca().add_patch(rect)\n",
        "    plt.title(\"Eye Detection\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # B. 눈 영역 확대 및 상세 분석 시각화\n",
        "    plt.subplot(1, 2, 2)\n",
        "    # 주변 30px 정도 여유를 두고 확대\n",
        "    crop_img = img_res[max(0, ymin-30):min(512, ymax+30), max(0, xmin-30):min(512, xmax+30)]\n",
        "    plt.imshow(crop_img)\n",
        "\n",
        "    # 텍스트 요약 up - 치켜올라감 flat - 평탄\n",
        "    shape_desc = 'long' if eye['l_ratio'] > 2.5 else 'circle'\n",
        "    tilt_desc = 'up' if eye['theta_tail'] > 5 else 'flat'\n",
        "\n",
        "    info_text = (f\"[Eye Analysis]\\n\"\n",
        "                 f\"Ratio: {eye['l_ratio']:.2f} ({shape_desc})\\n\"\n",
        "                 f\"Tilt: {eye['theta_tail']:.1f}° ({tilt_desc})\\n\"\n",
        "                 f\"Specular: {'Strong' if eye['specular'] else 'None'}\\n\"\n",
        "                 f\"Feature: {'Watery' if eye['is_watery'] else 'Clear'}\")\n",
        "\n",
        "    plt.text(5, 25, info_text, color='yellow', fontsize=11, fontweight='bold',\n",
        "             bbox=dict(facecolor='black', alpha=0.7))\n",
        "\n",
        "    plt.title(\"Detailed Eye Physiognomy\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # 터미널 결과 출력\n",
        "    print(f\"\\n--- 최종 분석 리포트 ---\")\n",
        "    print(f\"안광: {'눈빛이 형형하고 맑음' if eye['specular'] else '안광이 부족함'}\")\n",
        "    print(f\"특징: {'눈에 수분기가 있어 도화안의 기질이 있음' if eye['is_watery'] else '단정한 눈매'}\")\n",
        "else:\n",
        "    print(\"눈 영역 검출 실패\")"
      ],
      "metadata": {
        "id": "8bLfyZJjw5p1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 점 알고리즘"
      ],
      "metadata": {
        "id": "6NLWjrPyCHY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "# --- [1. SegFace 추론 함수 정의] ---\n",
        "def process_new_input(image_path, model, device, res=512):\n",
        "    orig_img = Image.open(image_path).convert('RGB')\n",
        "    img_resized = orig_img.resize((res, res))\n",
        "    img_tensor = torch.from_numpy(np.array(img_resized)).permute(2, 0, 1).float().div(255).unsqueeze(0).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # SegFace 특유의 forward 인자 대응 (None 전달)\n",
        "        output = model(img_tensor, labels=None, dataset=None)\n",
        "        if isinstance(output, (list, tuple)):\n",
        "            output = output[0]\n",
        "        pred_mask = torch.argmax(output, dim=1).squeeze(0).cpu().numpy()\n",
        "\n",
        "    return img_tensor.squeeze(0), pred_mask\n",
        "\n",
        "# --- [2. 피부 점 탐지 함수 정의] ---\n",
        "def detect_skin_moles(img_tensor, pred_mask):\n",
        "    # 텐서를 Numpy로 변환\n",
        "    img_np = (img_tensor.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)\n",
        "    gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # 2번 라벨(얼굴 피부)만 추출\n",
        "    face_area = (pred_mask == 2).astype(np.uint8)\n",
        "\n",
        "    # 전처리: 가우시안 블러로 미세 노이즈 제거\n",
        "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
        "\n",
        "    # Blackhat 연산: 밝은 배경에서 어두운 점 강조\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n",
        "    blackhat = cv2.morphologyEx(blurred, cv2.MORPH_BLACKHAT, kernel)\n",
        "\n",
        "    # 얼굴 영역으로 제한\n",
        "    masked_blackhat = cv2.bitwise_and(blackhat, blackhat, mask=face_area)\n",
        "\n",
        "    # 임계값 처리 및 컨투어 검출\n",
        "    _, mole_bin = cv2.threshold(masked_blackhat, 10, 255, cv2.THRESH_BINARY)\n",
        "    mole_mask = np.zeros_like(gray)\n",
        "    contours, _ = cv2.findContours(mole_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    for cnt in contours:\n",
        "        area = cv2.contourArea(cnt)\n",
        "        if 2 < area < 120: # 점 크기 필터\n",
        "            perimeter = cv2.arcLength(cnt, True)\n",
        "            if perimeter == 0: continue\n",
        "            circularity = 4 * np.pi * (area / (perimeter * perimeter))\n",
        "            if circularity > 0.6: # 원형도 필터\n",
        "                cv2.drawContours(mole_mask, [cnt], -1, 255, -1)\n",
        "\n",
        "    return img_np, mole_mask\n",
        "\n",
        "# --- [3. 메인 실행부] ---\n",
        "sample_image_path = '/content/h2_temp.jpg'\n",
        "\n",
        "if os.path.exists(sample_image_path):\n",
        "    # model과 device는 이미 선언되어 있어야 합니다 (SegFace 로드 셀 확인)\n",
        "    try:\n",
        "        # 1단계: SegFace 추론\n",
        "        img_tensor, p_mask = process_new_input(sample_image_path, model, device)\n",
        "\n",
        "        # 2단계: 점 탐지\n",
        "        img_raw, mole_result = detect_skin_moles(img_tensor, p_mask)\n",
        "\n",
        "        # 3단계: 시각화\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(img_raw)\n",
        "        plt.title(\"Original Face\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(img_raw)\n",
        "        mole_cmap = mcolors.ListedColormap([(0,0,0,0), 'red'])\n",
        "        plt.imshow(mole_result, cmap=mole_cmap, alpha=0.8)\n",
        "        plt.title(\"Detected Moles (Red Dots)\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "        # 결과 분석\n",
        "        num_moles = len(cv2.findContours(mole_result, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0])\n",
        "        print(f\"✅ 발견된 점/잡티 개수: {num_moles}개\")\n",
        "\n",
        "    except NameError as e:\n",
        "        print(f\"❌ 설정 에러: 모델(model)이 로드되지 않았습니다. {e}\")\n",
        "else:\n",
        "    print(f\"❌ 파일을 찾을 수 없습니다: {sample_image_path}\")"
      ],
      "metadata": {
        "id": "KDJjP054CJ4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 통합"
      ],
      "metadata": {
        "id": "yA_FDGXNyzVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "# 폰트 설정 (이전 단계에서 설치 완료 전제)\n",
        "font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "nanum_font = fm.FontProperties(fname=font_path)\n",
        "\n",
        "def analyze_face_physiognomy_full(img_path, model, device):\n",
        "    # 이미지 로드 및 전처리\n",
        "    img = Image.open(img_path).convert('RGB').resize((512, 512))\n",
        "    img_np = np.array(img)\n",
        "    gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    input_tensor = torch.from_numpy(img_np).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
        "    input_tensor = input_tensor.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor, None, None)\n",
        "        if isinstance(output, (list, tuple)): output = output[-1]\n",
        "        mask_res = torch.argmax(output, dim=1).squeeze().cpu().numpy()\n",
        "\n",
        "    # 마스크 분리\n",
        "    skin_m = (mask_res == 2).astype(np.uint8)\n",
        "    l_eb_m = (mask_res == 7).astype(np.uint8)\n",
        "    r_eb_m = (mask_res == 6).astype(np.uint8)\n",
        "    l_eye_m = (mask_res == 9).astype(np.uint8)\n",
        "\n",
        "    def get_info(m):\n",
        "        coords = np.column_stack(np.where(m > 0))\n",
        "        if len(coords) < 5: return None\n",
        "        return {'min_y': np.min(coords[:, 0]), 'max_y': np.max(coords[:, 0]),\n",
        "                'min_x': np.min(coords[:, 1]), 'max_x': np.max(coords[:, 1]), 'pts': coords}\n",
        "\n",
        "    res = {}\n",
        "    s_info, le_info, re_info, ly_info = get_info(skin_m), get_info(l_eb_m), get_info(r_eb_m), get_info(l_eye_m)\n",
        "\n",
        "    # --- 1. 이마 분석 (비율 + M자형) ---\n",
        "    if s_info and le_info:\n",
        "        brow_top_y = min(le_info['min_y'], re_info['min_y']) if re_info else le_info['min_y']\n",
        "        f_h = brow_top_y - s_info['min_y']\n",
        "        res['forehead'] = {'ratio': f_h / (s_info['max_y'] - s_info['min_y']), 'h': f_h, 'top_y': s_info['min_y'], 'brow_y': brow_top_y}\n",
        "        # M자형 판별\n",
        "        hairline = []\n",
        "        for x in range(s_info['min_x']+50, s_info['max_x']-50, 5):\n",
        "            y_vals = np.where(skin_m[:brow_top_y, x] > 0)[0]\n",
        "            if len(y_vals) > 0: hairline.append(y_vals[0])\n",
        "        res['forehead']['is_m'] = np.mean([hairline[0], hairline[-1]]) < hairline[len(hairline)//2] - 15 if len(hairline) > 10 else False\n",
        "\n",
        "    # --- 2. 눈썹 분석 (미간 + 기울기 + Y좌표 추가) ---\n",
        "    if le_info and re_info:\n",
        "        # 두 눈썹의 평균 Y축 중심값을 계산하여 시각화 기준으로 사용합니다.\n",
        "        brow_mid_y = (le_info['min_y'] + le_info['max_y'] + re_info['min_y'] + re_info['max_y']) // 4\n",
        "\n",
        "        res['brow'] = {\n",
        "            'glabella': re_info['min_x'] - le_info['max_x'],\n",
        "            'l_edge': le_info['max_x'],\n",
        "            'r_edge': re_info['min_x'],\n",
        "            'y': brow_mid_y  # <--- 이 부분이 누락되어 에러가 발생했습니다.\n",
        "        }\n",
        "\n",
        "        # 기울기 (왼쪽 눈썹 기준)\n",
        "        pts = le_info['pts']\n",
        "        head, tail = pts[np.argmin(pts[:, 1])], pts[np.argmax(pts[:, 1])]\n",
        "        res['brow']['tilt'] = np.degrees(np.arctan2(head[0] - tail[0], tail[1] - head[1]))\n",
        "\n",
        "    # --- 3. 눈 분석 (비율 + 전택궁 + 안광 + 수분감) ---\n",
        "    if ly_info and le_info:\n",
        "        eye_roi = gray[ly_info['min_y']:ly_info['max_y'], ly_info['min_x']:ly_info['max_x']]\n",
        "        res['eye'] = {\n",
        "            'palace': ly_info['min_y'] - le_info['max_y'],\n",
        "            'ratio': (ly_info['max_x']-ly_info['min_x']) / (ly_info['max_y']-ly_info['min_y']),\n",
        "            'specular': np.sum(cv2.threshold(eye_roi, 230, 255, cv2.THRESH_BINARY)[1]) > 0,\n",
        "            'watery': np.std(eye_roi) < 15 and np.mean(eye_roi) > 100,\n",
        "            'bbox': [ly_info['min_y'], ly_info['min_x'], ly_info['max_y'], ly_info['max_x']]\n",
        "        }\n",
        "\n",
        "    return img_np, mask_res, res\n",
        "\n",
        "# --- 2. 시각화 및 종합 리포트 ---\n",
        "\n",
        "def display_master_overlay_report(img, mask, res):\n",
        "    plt.figure(figsize=(20, 12))\n",
        "\n",
        "    # --- 왼쪽: 상세 측정 결과 오버레이 이미지 ---\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img)\n",
        "\n",
        "    # 1. 부위별 세그멘테이션 오버레이\n",
        "    ov = np.zeros((*img.shape[:2], 4), dtype=np.uint8)\n",
        "    ov[mask == 2] = [0, 255, 255, 30] # 이마/피부\n",
        "    ov[np.isin(mask, [6, 7])] = [255, 0, 0, 80] # 눈썹\n",
        "    ov[np.isin(mask, [8, 9])] = [0, 255, 0, 80] # 눈\n",
        "    plt.imshow(ov)\n",
        "\n",
        "    # 2. 이마 높이 측정선 (Yellow)\n",
        "    if 'forehead' in res:\n",
        "        f = res['forehead']\n",
        "        plt.annotate('', xy=(256, f['brow_y']), xytext=(256, f['top_y']),\n",
        "                     arrowprops=dict(arrowstyle='<->', color='yellow', lw=3))\n",
        "        plt.text(260, (f['top_y'] + f['brow_y']) // 2, f\"Forehead: {int(f['h'])}px\",\n",
        "                 color='yellow', fontproperties=nanum_font, fontsize=12, fontweight='bold')\n",
        "\n",
        "    # 3. 미간 너비 측정선 (Cyan)\n",
        "    if 'brow' in res:\n",
        "        b = res['brow']\n",
        "        plt.plot([b['l_edge'], b['r_edge']], [b['y'], b['y']], color='cyan', lw=3, marker='|', markersize=10)\n",
        "        plt.text((b['l_edge'] + b['r_edge']) // 2, b['y'] - 10, f\"Glabella: {b['glabella']}px\",\n",
        "                 color='cyan', fontproperties=nanum_font, fontsize=12, fontweight='bold', ha='center')\n",
        "\n",
        "        # 눈썹 기울기 가이드 (Magenta)\n",
        "        # 왼쪽 눈썹 끝부분에 각도 표시\n",
        "        plt.text(b['l_edge'] - 50, b['y'] - 30, f\"Tilt: {res['brow']['tilt']:.1f}°\",\n",
        "                 color='magenta', fontproperties=nanum_font, fontsize=11, fontweight='bold')\n",
        "\n",
        "    # 4. 전택궁 측정선 (White)\n",
        "    if 'eye' in res:\n",
        "        e = res['eye']\n",
        "        # 왼쪽 눈 중앙 기준 수직선\n",
        "        eye_x_mid = (e['bbox'][1] + e['bbox'][3]) // 2\n",
        "        plt.annotate('', xy=(eye_x_mid, e['bbox'][0]), xytext=(eye_x_mid, res['brow']['y']),\n",
        "                     arrowprops=dict(arrowstyle='->', color='white', lw=2))\n",
        "        plt.text(eye_x_mid + 5, (e['bbox'][0] + res['brow']['y']) // 2, f\"Palace: {e['palace']}px\",\n",
        "                 color='white', fontproperties=nanum_font, fontsize=11, fontweight='bold')\n",
        "\n",
        "    plt.title(\"◈ 상세 측정 지표 오버레이 ◈\", fontproperties=nanum_font, fontsize=18)\n",
        "    plt.axis('off')\n",
        "\n",
        "    # --- 오른쪽: 종합 분석 텍스트 리포트 ---\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.axis('off')\n",
        "    y_pos = 0.95\n",
        "    plt.text(0, y_pos, \"◈ 종합 관상 분석 리포트 ◈\", fontproperties=nanum_font, fontsize=22, fontweight='bold', color='navy')\n",
        "\n",
        "    if 'forehead' in res:\n",
        "        f = res['forehead']\n",
        "        y_pos -= 0.12\n",
        "        m_txt = \"M자형 (예술적 감각)\" if f['is_m'] else \"라운드/직선형 (안정적)\"\n",
        "        plt.text(0, y_pos, f\"■ 이마 (상정): 비율 {f['ratio']:.2f} | 형태: {m_txt}\\n   해석: {'이마가 넓어 관운과 총명이 따름' if f['ratio'] > 0.3 else '균형 잡힌 지성미'}\",\n",
        "                 fontproperties=nanum_font, fontsize=14)\n",
        "\n",
        "    if 'brow' in res:\n",
        "        b = res['brow']\n",
        "        y_pos -= 0.15\n",
        "        g_txt = \"넓은 미간 (개방적)\" if b['glabella'] > 45 else \"좁은 미간 (섬세함)\"\n",
        "        plt.text(0, y_pos, f\"■ 눈썹 (인당): 미간 {b['glabella']}px | 기울기 {b['tilt']:.1f}°\\n   해석: {g_txt}, {'눈썹이 올라가 강직한 성품' if b['tilt'] > 10 else '차분한 성품'}\",\n",
        "                 fontproperties=nanum_font, fontsize=14)\n",
        "\n",
        "    if 'eye' in res:\n",
        "        e = res['eye']\n",
        "        y_pos -= 0.18\n",
        "        s_txt = \"유 (총명함)\" if e['specular'] else \"무\"\n",
        "        w_txt = \"도화안 기질 (매력적)\" if e['watery'] else \"맑고 담백함\"\n",
        "        plt.text(0, y_pos, f\"■ 눈 (전택궁): 거리 {e['palace']}px | 비율 {e['ratio']:.2f}\\n   안광: {s_txt} | 특이사항: {w_txt}\\n   해석: {'전택궁이 넓어 주거 운이 좋음' if e['palace'] > 20 else '자수성가형 눈매'}\",\n",
        "                 fontproperties=nanum_font, fontsize=14)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 실행\n",
        "img_res, mask_res, final_res = analyze_face_physiognomy_full(\"/content/test9.jpg\", model, device)\n",
        "display_master_overlay_report(img_res, mask_res, final_res)\n"
      ],
      "metadata": {
        "id": "yrY7OCWMy0r7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
