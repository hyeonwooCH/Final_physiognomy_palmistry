{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0sMJdQnaOJf"
      },
      "outputs": [],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"jOcb5Y1QDeocxMBEA0Bi\")\n",
        "project = rf.workspace(\"dstu-dfliv\").project(\"palm-lines-recognition\")\n",
        "version = project.version(10)\n",
        "dataset = version.download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U ultralytics"
      ],
      "metadata": {
        "id": "Bd8qef3CaWtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# 1. 커스텀 MobileNetV3-Pose 모델 설정 (YAML 생성)\n",
        "# MobileNetV3-Small을 백본으로 사용하여 속도와 효율을 극대화합니다.\n",
        "mobilenet_yaml = \"\"\"\n",
        "# MobileNetV3-Small Pose Config\n",
        "nc: 5  # 데이터셋의 클래스 수 (palm-lines-recognition 기준)\n",
        "kpt_shape: [5, 2]  # 손금 주요 지점 수 (데이터셋에 맞게 자동 조정됨)\n",
        "\n",
        "backbone:\n",
        "  # [from, repeats, module, args]\n",
        "  - [-1, 1, Conv, [16, 3, 2]]  # 0-P1/2\n",
        "  - [-1, 1, Conv, [16, 3, 1]]  # 1\n",
        "  - [-1, 1, Conv, [24, 3, 2]]  # 2-P2/4\n",
        "  - [-1, 1, Conv, [24, 3, 1]]  # 3\n",
        "  - [-1, 1, Conv, [40, 3, 2]]  # 4-P3/8\n",
        "  - [-1, 3, Conv, [40, 3, 1]]  # 5\n",
        "  - [-1, 1, Conv, [80, 3, 2]]  # 6-P4/16\n",
        "  - [-1, 3, Conv, [80, 3, 1]]  # 7\n",
        "  - [-1, 1, Conv, [112, 3, 1]] # 8\n",
        "  - [-1, 1, Conv, [112, 3, 1]] # 9\n",
        "  - [-1, 1, Conv, [160, 3, 2]] # 10-P5/32\n",
        "  - [-1, 1, SPPF, [1024, 5]]   # 11\n",
        "\n",
        "head:\n",
        "  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]\n",
        "  - [[-1, 9], 1, Concat, [1]]  # cat backbone P4\n",
        "  - [-1, 3, C2f, [112]]        # 14\n",
        "\n",
        "  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]\n",
        "  - [[-1, 5], 1, Concat, [1]]  # cat backbone P3\n",
        "  - [-1, 3, C2f, [40]]         # 17 (P3/8-small)\n",
        "\n",
        "  - [-1, 1, Conv, [40, 3, 2]]\n",
        "  - [[-1, 14], 1, Concat, [1]] # cat head P4\n",
        "  - [-1, 3, C2f, [112]]        # 20 (P4/16-medium)\n",
        "\n",
        "  - [-1, 1, Conv, [112, 3, 2]]\n",
        "  - [[-1, 11], 1, Concat, [1]] # cat head P5\n",
        "  - [-1, 3, C2f, [256]]        # 23 (P5/32-large)\n",
        "\n",
        "  - [[17, 20, 23], 1, Pose, [nc, kpt_shape]] # Pose head\n",
        "\"\"\"\n",
        "\n",
        "with open('mobilenet_pose.yaml', 'w') as f:\n",
        "    f.write(mobilenet_yaml)\n",
        "\n",
        "# 2. 명암 대비 전처리 (CLAHE 1.2 - 낮게 설정)\n",
        "def apply_low_clahe(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None: return None\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    # clipLimit를 1.2로 낮춰서 노이즈를 억제하고 선만 뚜렷하게 함\n",
        "    clahe = cv2.createCLAHE(clipLimit=1.2, tileGridSize=(8, 8))\n",
        "    cl = clahe.apply(l)\n",
        "    return cv2.cvtColor(cv2.merge((cl, a, b)), cv2.COLOR_LAB2BGR)\n",
        "\n",
        "# 3. 모델 학습 (100에폭, Mosaic/Mixup Off)\n",
        "model = YOLO('mobilenet_pose.yaml') # 위에서 만든 MobileNet 구조 로드\n",
        "\n",
        "model.train(\n",
        "    data='Palm-lines-recognition-10/data.yaml',\n",
        "    epochs=100,\n",
        "    imgsz=640,\n",
        "    mosaic=0.0,   # 모자이크 끄기\n",
        "    mixup=0.0,    # 믹스업 끄기\n",
        "    name='palm_mobilenet',\n",
        "    save=True\n",
        ")\n",
        "\n",
        "# 4. 베스트 모델을 num_02.pt로 저장\n",
        "best_path = os.path.join(model.trainer.save_dir, 'weights/best.pt')\n",
        "shutil.copy(best_path, 'num_02.pt')\n",
        "print(\"✅ MobileNet-Pose 모델 저장 완료: num_02.pt\")\n",
        "\n",
        "# 5. 시각화 함수 (같은 클래스 동일 색상 적용)\n",
        "def visualize_test(image_path):\n",
        "    processed_img = apply_low_clahe(image_path)\n",
        "    trained_model = YOLO('num_02.pt')\n",
        "    results = trained_model.predict(processed_img, conf=0.25)[0]\n",
        "\n",
        "    names = results.names\n",
        "    # 고정 색상 맵 (클래스별로 다른 색상 지정)\n",
        "    cmap = plt.cm.get_cmap('hsv', len(names))\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(cv2.cvtColor(processed_img, cv2.COLOR_BGR2RGB))\n",
        "    ax = plt.gca()\n",
        "\n",
        "    if results.boxes is not None:\n",
        "        for i, box in enumerate(results.boxes):\n",
        "            cls_id = int(box.cls[0])\n",
        "            color = cmap(cls_id)\n",
        "\n",
        "            # 박스 및 키포인트(히트맵 기반 포인트) 표시\n",
        "            b = box.xyxy[0].cpu().numpy()\n",
        "            ax.add_patch(plt.Rectangle((b[0], b[1]), b[2]-b[0], b[3]-b[1],\n",
        "                                     fill=False, edgecolor=color, linewidth=2))\n",
        "\n",
        "            if results.keypoints is not None:\n",
        "                pts = results.keypoints.xy[i].cpu().numpy()\n",
        "                for pt in pts:\n",
        "                    if pt[0] > 0:\n",
        "                        plt.scatter(pt[0], pt[1], color=color, s=30, edgecolors='white')\n",
        "\n",
        "            ax.text(b[0], b[1]-5, f\"{names[cls_id]}\", color='white', fontsize=10,\n",
        "                    bbox=dict(facecolor=color, alpha=0.8, edgecolor='none'))\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# 실행 예시 (테스트용 이미지 경로 입력)\n",
        "# visualize_test('test_image.jpg')"
      ],
      "metadata": {
        "id": "mwU0QbbLaYt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#시각화\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "from google.colab import files  # 코랩 전용 파일 업로드 모듈\n",
        "import io\n",
        "\n",
        "def colab_visualize_palm(model_path='num_02.pt'):\n",
        "    # 1. 파일 업로드 인터페이스 띄우기\n",
        "    print(\"시각화할 손 이미지를 업로드하세요.\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"파일이 선택되지 않았습니다.\")\n",
        "        return\n",
        "\n",
        "    # 2. 모델 로드 (학습된 num_02.pt)\n",
        "    # 만약 파일이 없다면 num01.pt나 yolo11n-pose.pt 등으로 이름을 바꿔주세요.\n",
        "    try:\n",
        "        model = YOLO(model_path)\n",
        "    except:\n",
        "        print(f\"❌ {model_path} 파일을 찾을 수 없습니다. 파일 이름을 확인해주세요.\")\n",
        "        return\n",
        "\n",
        "    # 3. 업로드된 파일 처리\n",
        "    for filename in uploaded.keys():\n",
        "        # 이미지 읽기\n",
        "        file_bytes = np.frombuffer(uploaded[filename], dtype=np.uint8)\n",
        "        img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n",
        "\n",
        "        if img is None: continue\n",
        "\n",
        "        # 4. 전처리 (CLAHE 1.2 - 낮은 강도)\n",
        "        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "        l, a, b = cv2.split(lab)\n",
        "        clahe = cv2.createCLAHE(clipLimit=1.2, tileGridSize=(8, 8))\n",
        "        cl = clahe.apply(l)\n",
        "        processed_img = cv2.cvtColor(cv2.merge((cl, a, b)), cv2.COLOR_LAB2BGR)\n",
        "\n",
        "        # 5. 모델 예측\n",
        "        results = model.predict(processed_img, conf=0.25)[0]\n",
        "        names = results.names\n",
        "\n",
        "        # 6. 클래스별 고정 색상 설정 (동일 클래스 = 동일 색상)\n",
        "        class_colors = [\n",
        "            (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0),\n",
        "            (255, 0, 255), (0, 255, 255), (255, 165, 0), (128, 0, 128)\n",
        "        ]\n",
        "\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.imshow(cv2.cvtColor(processed_img, cv2.COLOR_BGR2RGB))\n",
        "        ax = plt.gca()\n",
        "\n",
        "        if results.boxes is not None:\n",
        "            for i, box in enumerate(results.boxes):\n",
        "                cls_id = int(box.cls[0])\n",
        "                base_color = class_colors[cls_id % len(class_colors)]\n",
        "                color_plt = tuple(c/255 for c in base_color)\n",
        "\n",
        "                # 박스 시각화\n",
        "                b = box.xyxy[0].cpu().numpy()\n",
        "                ax.add_patch(plt.Rectangle((b[0], b[1]), b[2]-b[0], b[3]-b[1],\n",
        "                                         fill=False, edgecolor=color_plt, linewidth=3))\n",
        "\n",
        "                # 키포인트(손금 점) 시각화\n",
        "                if results.keypoints is not None:\n",
        "                    kpts = results.keypoints.xy[i].cpu().numpy()\n",
        "                    for pt in kpts:\n",
        "                        if pt[0] > 0:\n",
        "                            plt.scatter(pt[0], pt[1], color=color_plt, s=40, edgecolors='white', zorder=5)\n",
        "\n",
        "                # 라벨 배경색 고정\n",
        "                ax.text(b[0], b[1]-10, f\"{names[cls_id]}\", color='white', fontweight='bold',\n",
        "                        bbox=dict(facecolor=color_plt, edgecolor='none', alpha=0.8))\n",
        "\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"Result: {filename}\", fontsize=12)\n",
        "        plt.show()\n",
        "\n",
        "# 실행\n",
        "colab_visualize_palm('num_02.pt')"
      ],
      "metadata": {
        "id": "ztg01plsaauE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 라이브러리 설치\n",
        "!pip install ultralytics\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 2. 모델 로드\n",
        "model_path = '/content/num_02.pt'\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# 3. 클래스별 고유 색상 매핑 (BGR 순서: (B, G, R))\n",
        "# 모델의 클래스 순서에 맞춰 원하는 색상을 지정하세요.\n",
        "# 예: 0번은 빨강, 1번은 노랑, 2번은 파랑...\n",
        "CLASS_COLORS = [\n",
        "    (0, 0, 255),    # 0번: 빨강\n",
        "    (0, 255, 255),  # 1번: 노랑\n",
        "    (255, 0, 0),    # 2번: 파랑\n",
        "    (0, 255, 0),    # 3번: 초록\n",
        "    (255, 0, 255),  # 4번: 보라\n",
        "    (255, 255, 0),  # 5번: 하늘색\n",
        "]\n",
        "\n",
        "# 4. 사진 업로드\n",
        "print(\"손금 사진을 업로드해주세요.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "FATE_KEYWORD = 'fate' # 모델에 따라 '운명선' 등으로 변경 가능\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    results = model.predict(source=filename, conf=0.2, save=False)\n",
        "\n",
        "    img = cv2.imread(filename)\n",
        "    names = model.names\n",
        "    fate_ids = [k for k, v in names.items() if FATE_KEYWORD in v.lower()]\n",
        "\n",
        "    for r in results:\n",
        "        if r.keypoints is None: continue\n",
        "\n",
        "        kpts = r.keypoints.data.cpu().numpy()\n",
        "        classes = r.boxes.cls.cpu().numpy().astype(int)\n",
        "\n",
        "        fate_kpts_list = []\n",
        "        fate_color = (255, 255, 255)\n",
        "\n",
        "        # --- 일반 손금 및 데이터 수집 ---\n",
        "        for i, cls_id in enumerate(classes):\n",
        "            color = CLASS_COLORS[cls_id % len(CLASS_COLORS)]\n",
        "\n",
        "            if cls_id in fate_ids:\n",
        "                fate_kpts_list.append(kpts[i])\n",
        "                fate_color = color\n",
        "            else:\n",
        "                # 점(Keypoint)과 선 그리기\n",
        "                points = kpts[i]\n",
        "                for j in range(len(points)):\n",
        "                    x, y, conf = points[j]\n",
        "                    if conf > 0.3: # 신뢰도 기준\n",
        "                        # 1. 선 그리기 (다음 점과 연결)\n",
        "                        if j < len(points) - 1:\n",
        "                            nx, ny, nconf = points[j+1]\n",
        "                            if nconf > 0.3:\n",
        "                                cv2.line(img, (int(x), int(y)), (int(nx), int(ny)), color, 5)\n",
        "                        # 2. 점 그리기 (원하는 스타일)\n",
        "                        cv2.circle(img, (int(x), int(y)), 8, color, -1) # 채워진 원\n",
        "                        cv2.circle(img, (int(x), int(y)), 10, (255, 255, 255), 2) # 테두리\n",
        "\n",
        "        # --- 운명선 통합 (두 줄을 하나로) ---\n",
        "        if len(fate_kpts_list) > 0:\n",
        "            merged_fate = np.mean(fate_kpts_list, axis=0)\n",
        "            for j in range(len(merged_fate)):\n",
        "                x, y, conf = merged_fate[j]\n",
        "                if conf > 0.1:\n",
        "                    if j < len(merged_fate) - 1:\n",
        "                        nx, ny, nconf = merged_fate[j+1]\n",
        "                        if nconf > 0.1:\n",
        "                            cv2.line(img, (int(x), int(y)), (int(nx), int(ny)), fate_color, 8) # 더 두껍게\n",
        "                    cv2.circle(img, (int(x), int(y)), 10, fate_color, -1)\n",
        "                    cv2.circle(img, (int(x), int(y)), 12, (255, 255, 255), 2)\n",
        "\n",
        "    # 결과 시각화\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "T9804VrYajtt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}