{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1r1qyMBOztca+H/8uuY3C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyeonwooCH/Final_physiognomy_palmistry/blob/main/mole_alg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì½”ë© ì…€ì— ì´ ì½”ë“œ ë¶™ì´ê¸°\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image, ImageOps\n",
        "import subprocess\n",
        "\n",
        "# ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ\n",
        "input_image_path = \"/content/hyunj.jpg\"\n",
        "\n",
        "# EXIF íšŒì „ ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì €ì¥í•  ì„ì‹œ ê²½ë¡œ\n",
        "fixed_image_path = \"/content/h_temp.jpg\"\n",
        "\n",
        "# 1ë‹¨ê³„: EXIF ì²˜ë¦¬\n",
        "img = Image.open(input_image_path)\n",
        "img = ImageOps.exif_transpose(img)  # â˜… íšŒì „ ì ìš©\n",
        "img.save(fixed_image_path)\n",
        "\n",
        "print(\"âœ… EXIF ì²˜ë¦¬ + ì¶”ë¡  ì™„ë£Œ!\")\n"
      ],
      "metadata": {
        "id": "ZK4yA3-tyycB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uhsCY2orw9w2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. SegFace ì €ì¥ì†Œ í´ë¡  ë° ì´ë™\n",
        "!git clone https://github.com/Kartik-3004/SegFace.git\n",
        "%cd SegFace\n",
        "\n",
        "# 2. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (ì½”ë© í™˜ê²½ ìµœì í™” ë²„ì „)\n",
        "!pip install -q timm==0.9.12 segmentation-models-pytorch albumentations python-dotenv huggingface_hub"
      ],
      "metadata": {
        "id": "ypH9S2eFx5Zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# 1. .env ê²½ë¡œ ì„¤ì • íŒŒì¼ ìƒì„±\n",
        "root_path = \"/content/SegFace\"\n",
        "with open(\".env\", \"w\") as f:\n",
        "    f.write(f\"ROOT_PATH={root_path}\\n\")\n",
        "    f.write(f\"DATA_PATH={root_path}/data\\n\")\n",
        "    f.write(f\"LOG_PATH={root_path}/logs\\n\")\n",
        "\n",
        "# 2. ê°€ì¤‘ì¹˜(Weights) ë‹¤ìš´ë¡œë“œ\n",
        "hf_hub_download(repo_id=\"kartiknarayan/SegFace\",\n",
        "                filename=\"convnext_celeba_512/model_299.pt\",\n",
        "                local_dir=\"./weights\")\n",
        "\n",
        "print(\"âœ… í™˜ê²½ ì„¤ì • ë° ê°€ì¤‘ì¹˜ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!\")"
      ],
      "metadata": {
        "id": "4rm_IclYx7QR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import sys\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸ ê²½ë¡œ ì¶”ê°€\n",
        "if '/content/SegFace' not in sys.path:\n",
        "    sys.path.append('/content/SegFace')\n",
        "from network.models.segface_celeb import SegFaceCeleb\n",
        "\n",
        "# --- [ì„¤ì • ì˜ì—­] ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_path = \"/content/SegFace/weights/convnext_celeba_512/model_299.pt\"\n",
        "input_res = 512\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸í•  ë°ì´í„° ê²½ë¡œ (ë³¸ì¸ì˜ ê²½ë¡œë¡œ ìˆ˜ì •í•˜ì„¸ìš”)\n",
        "# ì˜ˆ: /content/drive/MyDrive/test_data/images\n",
        "test_images_path = \"/content/drive/MyDrive/c. Final_Team/Split_dataset/test/images\"\n",
        "test_masks_path = \"/content/drive/MyDrive/c. Final_Team/Split_dataset/test/masks\"\n",
        "\n",
        "# ìˆ˜ì •ëœ class_names (SegFace ëª¨ë¸ ì¶œë ¥ ìˆœì„œ)\n",
        "class_names = [\n",
        "    'bg', 'neck', 'face', 'cloth', 'lr', 'rr', 'lb', 'rb', 'le',\n",
        "    're', 'nose', 'imouth', 'llip', 'ulip', 'hair',\n",
        "    'glass', 'hat', 'earr', 'neckl'\n",
        "]\n",
        "# ------------------\n",
        "\n",
        "\n",
        "\n",
        "AI_HUB_TO_SEGFACE =  {\n",
        "    0: 0, 1: 2, 2: 7, 3: 6, 4: 9, 5: 8, 6: 15, 7: 5, 8: 4, 9: 17,\n",
        "    10: 10, 11: 11, 12: 13, 13: 12, 14: 1, 15: 18, 16: 3, 17: 14, 18: 16,\n",
        "}\n",
        "\n",
        "# 1. ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜\n",
        "def load_segface_model():\n",
        "    model = SegFaceCeleb(input_res, \"convnext_base\")\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "    pretrained_dict = checkpoint.get('state_dict_backbone', checkpoint.get('model_state_dict', checkpoint))\n",
        "    model.load_state_dict(pretrained_dict, strict=False)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# 2. ë‹¤ì¤‘ ë°ì´í„° ë¡œë” í´ë˜ìŠ¤\n",
        "class SegFaceEvalDataset(Dataset):\n",
        "    def __init__(self, img_dir, mask_dir, res=512):\n",
        "        import glob\n",
        "        import os\n",
        "        self.img_paths = sorted(glob.glob(os.path.join(img_dir, \"*.*\")))\n",
        "        self.mask_paths = sorted(glob.glob(os.path.join(mask_dir, \"*.*\")))\n",
        "        self.res = res\n",
        "    def __len__(self): return len(self.img_paths)\n",
        "\n",
        "    def align_aihub_labels(self, mask_np):\n",
        "        \"\"\"AI í—ˆë¸Œ IDë¥¼ SegFace IDë¡œ ì¬ë°°ì—´\"\"\"\n",
        "        new_mask = np.zeros_like(mask_np)\n",
        "        for ai_id, seg_id in AI_HUB_TO_SEGFACE.items():\n",
        "            new_mask[mask_np == ai_id] = seg_id\n",
        "        return new_mask\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 1. ì´ë¯¸ì§€ ë¡œë“œ\n",
        "        img = Image.open(self.img_paths[idx]).convert('RGB').resize((self.res, self.res))\n",
        "        img_tensor = torch.from_numpy(np.array(img)).permute(2, 0, 1).float().div(255)\n",
        "\n",
        "        # 2. ë§ˆìŠ¤í¬ ë¡œë“œ (AI í—ˆë¸Œ Grayscale ëŒ€ì‘)\n",
        "        mask = Image.open(self.mask_paths[idx]).convert('L')\n",
        "        mask = mask.resize((self.res, self.res), Image.NEAREST)\n",
        "        mask_np = np.array(mask).astype(np.int64)\n",
        "\n",
        "        # ğŸ’¡ [í•µì‹¬] AI í—ˆë¸Œ ë°ì´í„° ì „ì²˜ë¦¬\n",
        "        # ë§Œì•½ AI í—ˆë¸Œ ë°ì´í„°ê°€ 0, 1, 2... ìˆœì„œê°€ ì•„ë‹ˆë¼\n",
        "        # ì‹œê°í™”ë¥¼ ìœ„í•´ í° ê°’(ì˜ˆ: 10, 20...)ì„ ê°€ì§€ê³  ìˆë‹¤ë©´ ì •ê·œí™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
        "        # ê³ ìœ ê°’ì„ í™•ì¸í•œ í›„ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”.\n",
        "        mask_np = self.align_aihub_labels(mask_np)\n",
        "\n",
        "        mask_tensor = torch.from_numpy(mask_np).long()\n",
        "        return img_tensor, mask_tensor, os.path.basename(self.img_paths[idx])\n",
        "\n"
      ],
      "metadata": {
        "id": "_Sz5ys7qx_7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "class FaceParsingDataset(Dataset):\n",
        "    def __init__(self, root_path, mode='test'):\n",
        "        self.img_dir = os.path.join(root_path, mode, 'images')\n",
        "        self.mask_dir = os.path.join(root_path, mode, 'masks')\n",
        "        # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ë¡œë“œ\n",
        "        self.file_list = [f for f in sorted(os.listdir(self.img_dir)) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.file_list[idx]\n",
        "\n",
        "        # íŒŒì¼ëª…ì—ì„œ í™•ì¥ìë¥¼ ì œì™¸í•œ ì´ë¦„ ì¶”ì¶œ (ì˜ˆ: '0174' -> '0174_grayscale.png')\n",
        "        base_name = os.path.splitext(img_name)[0]\n",
        "        mask_name = f\"{base_name}_grayscale.png\"\n",
        "\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        mask_path = os.path.join(self.mask_dir, mask_name)\n",
        "\n",
        "        # ì´ë¯¸ì§€ ë° ë§ˆìŠ¤í¬ ë¡œë“œ\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        mask = Image.open(mask_path)\n",
        "\n",
        "        # í…ì„œ ë³€í™˜: [C, H, W] í˜•íƒœ ë° 0~1 ì •ê·œí™”\n",
        "        img_tensor = torch.from_numpy(np.array(img)).permute(2, 0, 1).float() / 255.0\n",
        "        mask_np = np.array(mask)\n",
        "\n",
        "        return img_tensor, mask_np, img_name\n",
        "\n",
        "# ê²½ë¡œ ì„¤ì • (ì‹¤ì œ ê²½ë¡œë¡œ ìˆ˜ì • í•„ìš”)\n",
        "BASE_PATH = '/content/drive/MyDrive/c. Final_Team/Split_dataset'\n",
        "dataset = FaceParsingDataset(BASE_PATH, mode='test')\n",
        "print(f\"Dataset ë¡œë“œ ì™„ë£Œ: {len(dataset)} ê°œì˜ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "# 1. ëª¨ë¸ ë¡œë“œ (ì‘ì„±í•˜ì‹  load_segface_model í•¨ìˆ˜ í˜¸ì¶œ)\n",
        "model = load_segface_model()\n",
        "\n",
        "# 2. ì¥ì¹˜ ì„¤ì • í™•ì¸ (ìœ„ ì„¤ì • ì˜ì—­ì— ìˆì§€ë§Œ ë‹¤ì‹œ í•œ ë²ˆ í™•ì‹¤íˆ)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! ì¥ì¹˜: {device}\")"
      ],
      "metadata": {
        "id": "0K37ocRfxBAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21-n-6hwwy7k"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "# --- [1. SegFace ì¶”ë¡  í•¨ìˆ˜ ì •ì˜] ---\n",
        "def process_new_input(image_path, model, device, res=512):\n",
        "    orig_img = Image.open(image_path).convert('RGB')\n",
        "    img_resized = orig_img.resize((res, res))\n",
        "    img_tensor = torch.from_numpy(np.array(img_resized)).permute(2, 0, 1).float().div(255).unsqueeze(0).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # SegFace íŠ¹ìœ ì˜ forward ì¸ì ëŒ€ì‘ (None ì „ë‹¬)\n",
        "        output = model(img_tensor, labels=None, dataset=None)\n",
        "        if isinstance(output, (list, tuple)):\n",
        "            output = output[0]\n",
        "        pred_mask = torch.argmax(output, dim=1).squeeze(0).cpu().numpy()\n",
        "\n",
        "    return img_tensor.squeeze(0), pred_mask\n",
        "\n",
        "# --- [2. í”¼ë¶€ ì  íƒì§€ í•¨ìˆ˜ ì •ì˜] ---\n",
        "def detect_skin_moles(img_tensor, pred_mask):\n",
        "    # í…ì„œë¥¼ Numpyë¡œ ë³€í™˜\n",
        "    img_np = (img_tensor.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)\n",
        "    gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # 2ë²ˆ ë¼ë²¨(ì–¼êµ´ í”¼ë¶€)ë§Œ ì¶”ì¶œ\n",
        "    face_area = (pred_mask == 2).astype(np.uint8)\n",
        "\n",
        "    # ì „ì²˜ë¦¬: ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë¯¸ì„¸ ë…¸ì´ì¦ˆ ì œê±°\n",
        "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
        "\n",
        "    # Blackhat ì—°ì‚°: ë°ì€ ë°°ê²½ì—ì„œ ì–´ë‘ìš´ ì  ê°•ì¡°\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n",
        "    blackhat = cv2.morphologyEx(blurred, cv2.MORPH_BLACKHAT, kernel)\n",
        "\n",
        "    # ì–¼êµ´ ì˜ì—­ìœ¼ë¡œ ì œí•œ\n",
        "    masked_blackhat = cv2.bitwise_and(blackhat, blackhat, mask=face_area)\n",
        "\n",
        "    # ì„ê³„ê°’ ì²˜ë¦¬ ë° ì»¨íˆ¬ì–´ ê²€ì¶œ\n",
        "    _, mole_bin = cv2.threshold(masked_blackhat, 10, 255, cv2.THRESH_BINARY)\n",
        "    mole_mask = np.zeros_like(gray)\n",
        "    contours, _ = cv2.findContours(mole_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    for cnt in contours:\n",
        "        area = cv2.contourArea(cnt)\n",
        "        if 2 < area < 120: # ì  í¬ê¸° í•„í„°\n",
        "            perimeter = cv2.arcLength(cnt, True)\n",
        "            if perimeter == 0: continue\n",
        "            circularity = 4 * np.pi * (area / (perimeter * perimeter))\n",
        "            if circularity > 0.6: # ì›í˜•ë„ í•„í„°\n",
        "                cv2.drawContours(mole_mask, [cnt], -1, 255, -1)\n",
        "\n",
        "    return img_np, mole_mask\n",
        "\n",
        "# --- [3. ë©”ì¸ ì‹¤í–‰ë¶€] ---\n",
        "sample_image_path = '/content/h_temp.jpg'\n",
        "\n",
        "if os.path.exists(sample_image_path):\n",
        "    # modelê³¼ deviceëŠ” ì´ë¯¸ ì„ ì–¸ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤ (SegFace ë¡œë“œ ì…€ í™•ì¸)\n",
        "    try:\n",
        "        # 1ë‹¨ê³„: SegFace ì¶”ë¡ \n",
        "        img_tensor, p_mask = process_new_input(sample_image_path, model, device)\n",
        "\n",
        "        # 2ë‹¨ê³„: ì  íƒì§€\n",
        "        img_raw, mole_result = detect_skin_moles(img_tensor, p_mask)\n",
        "\n",
        "        # 3ë‹¨ê³„: ì‹œê°í™”\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(img_raw)\n",
        "        plt.title(\"Original Face\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(img_raw)\n",
        "        mole_cmap = mcolors.ListedColormap([(0,0,0,0), 'red'])\n",
        "        plt.imshow(mole_result, cmap=mole_cmap, alpha=0.8)\n",
        "        plt.title(\"Detected Moles (Red Dots)\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "        # ê²°ê³¼ ë¶„ì„\n",
        "        num_moles = len(cv2.findContours(mole_result, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0])\n",
        "        print(f\"âœ… ë°œê²¬ëœ ì /ì¡í‹° ê°œìˆ˜: {num_moles}ê°œ\")\n",
        "\n",
        "    except NameError as e:\n",
        "        print(f\"âŒ ì„¤ì • ì—ëŸ¬: ëª¨ë¸(model)ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. {e}\")\n",
        "else:\n",
        "    print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {sample_image_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QmhRQenpw3ZI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}